{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":61542,"databundleVersionId":6888007,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries and Download NLTK Resources","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom collections import defaultdict\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport re\n\n# Download necessary NLTK resources\nnltk.download('punkt')\nnltk.download('stopwords')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-12-03T17:57:58.474618Z","iopub.execute_input":"2023-12-03T17:57:58.476289Z","iopub.status.idle":"2023-12-03T17:58:01.717907Z","shell.execute_reply.started":"2023-12-03T17:57:58.476208Z","shell.execute_reply":"2023-12-03T17:58:01.716503Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"#  Define Text Preprocessing Functions","metadata":{}},{"cell_type":"code","source":"# Function to preprocess text\ndef preprocess_text(text):\n    text = text.lower()  # Lowercase\n    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n    tokens = word_tokenize(text)  # Tokenize\n    tokens = [word for word in tokens if word.isalpha()]  # Remove non-alphabetic tokens\n    stop_words = set(stopwords.words('english'))  # Stopwords\n    tokens = [word for word in tokens if word not in stop_words]  # Remove stopwords\n    return tokens\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T17:58:21.580651Z","iopub.execute_input":"2023-12-03T17:58:21.581307Z","iopub.status.idle":"2023-12-03T17:58:21.590361Z","shell.execute_reply.started":"2023-12-03T17:58:21.581268Z","shell.execute_reply":"2023-12-03T17:58:21.588481Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Define Vocabulary Building Function","metadata":{}},{"cell_type":"code","source":"# Function to build vocabulary\ndef build_vocabulary(data):\n    vocabulary = defaultdict(int)\n    for text in data:\n        for word in text:\n            vocabulary[word] += 1\n    return {word: index for index, word in enumerate(vocabulary) if vocabulary[word] >= 5}\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T17:58:34.550524Z","iopub.execute_input":"2023-12-03T17:58:34.552264Z","iopub.status.idle":"2023-12-03T17:58:34.559086Z","shell.execute_reply.started":"2023-12-03T17:58:34.552203Z","shell.execute_reply":"2023-12-03T17:58:34.557885Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# Define Naive Bayes Classifier Training Function","metadata":{}},{"cell_type":"code","source":"# Function to train Naive Bayes Classifier\ndef train_naive_bayes(data, vocab):\n    word_counts = {class_: defaultdict(int) for class_ in np.unique(data['generated'])}\n    class_counts = defaultdict(int)\n\n    for _, row in data.iterrows():\n        label = row['generated']\n        class_counts[label] += 1\n        for word in row['processed_text']:\n            if word in vocab:\n                word_counts[label][word] += 1\n\n    total_docs = len(data)\n    word_probs = {class_: {word: (word_counts[class_][word] + 1) / (class_counts[class_] + len(vocab))\n                           for word in vocab}\n                  for class_ in word_counts}\n    class_probs = {class_: class_counts[class_] / total_docs for class_ in class_counts}\n\n    return class_probs, word_probs\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T17:58:46.336316Z","iopub.execute_input":"2023-12-03T17:58:46.336819Z","iopub.status.idle":"2023-12-03T17:58:46.353003Z","shell.execute_reply.started":"2023-12-03T17:58:46.336782Z","shell.execute_reply":"2023-12-03T17:58:46.345677Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Define Classification Function","metadata":{}},{"cell_type":"code","source":"# Function to classify new instances\ndef classify(text, class_probs, word_probs, vocab):\n    text_words = set(preprocess_text(text))\n    class_scores = {class_: np.log(class_prob) for class_, class_prob in class_probs.items()}\n    for class_, word_prob in word_probs.items():\n        for word in text_words:\n            if word in vocab:\n                class_scores[class_] += np.log(word_prob.get(word, 1 / (len(vocab) + sum(word_prob.values()))))\n\n    return max(class_scores, key=class_scores.get)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T17:58:58.601479Z","iopub.execute_input":"2023-12-03T17:58:58.601927Z","iopub.status.idle":"2023-12-03T17:58:58.610425Z","shell.execute_reply.started":"2023-12-03T17:58:58.601892Z","shell.execute_reply":"2023-12-03T17:58:58.608869Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Load and Preprocess Data","metadata":{}},{"cell_type":"code","source":"# Load and preprocess the data\nessays = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_essays.csv')\nprompts = pd.read_csv('/kaggle/input/llm-detect-ai-generated-text/train_prompts.csv')\nmerged_data = pd.merge(essays, prompts, on='prompt_id')\n\n# Preprocessing texts\nmerged_data['processed_text'] = merged_data['text'].apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:05:27.315731Z","iopub.execute_input":"2023-12-03T18:05:27.316263Z","iopub.status.idle":"2023-12-03T18:05:39.851833Z","shell.execute_reply.started":"2023-12-03T18:05:27.316224Z","shell.execute_reply":"2023-12-03T18:05:39.849879Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Split Data and Build Vocabulary","metadata":{}},{"cell_type":"code","source":"# Splitting the data\ntrain_data = merged_data.sample(frac=0.8, random_state=1)\ndev_data = merged_data.drop(train_data.index)\n\n# Building vocabulary from training data\nvocab = build_vocabulary(train_data['processed_text'])","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:05:55.683339Z","iopub.execute_input":"2023-12-03T18:05:55.683878Z","iopub.status.idle":"2023-12-03T18:05:55.794054Z","shell.execute_reply.started":"2023-12-03T18:05:55.683839Z","shell.execute_reply":"2023-12-03T18:05:55.793034Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Train Naive Bayes Classifier and Evaluate on Development Data","metadata":{}},{"cell_type":"code","source":"# Training the Naive Bayes Classifier\nclass_probs, word_probs = train_naive_bayes(train_data, vocab)\n\n# Evaluating the classifier on development data\ndev_data['predicted'] = dev_data['text'].apply(lambda text: classify(text, class_probs, word_probs, vocab))\naccuracy = np.mean(dev_data['predicted'] == dev_data['generated'])\nprint(f'Accuracy on development set: {accuracy*100}%')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:06:10.195875Z","iopub.execute_input":"2023-12-03T18:06:10.196321Z","iopub.status.idle":"2023-12-03T18:06:18.143995Z","shell.execute_reply.started":"2023-12-03T18:06:10.196288Z","shell.execute_reply":"2023-12-03T18:06:18.142693Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Accuracy on development set: 99.27536231884058%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Probability of the word \"the\"","metadata":{}},{"cell_type":"code","source":"# Assuming vocab is already defined\nword_of_interest = \"the\"\n\n# Calculate the probability\nprobability_of_word = vocab.get(word_of_interest, 0) / len(vocab)\n\n# Print the result\nprint(f'Probability of the word \"{word_of_interest}\": {probability_of_word}')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:06:31.620101Z","iopub.execute_input":"2023-12-03T18:06:31.620650Z","iopub.status.idle":"2023-12-03T18:06:31.629628Z","shell.execute_reply.started":"2023-12-03T18:06:31.620604Z","shell.execute_reply":"2023-12-03T18:06:31.627963Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Probability of the word \"the\": 0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Conditional Probability based on the class","metadata":{}},{"cell_type":"code","source":"llm_data = merged_data[merged_data['generated'] == 1]\np_the_llm = llm_data['processed_text'].apply(lambda text: \"the\" in text).mean()\nprint(f'Conditional probability of \"the\" given LLM: {p_the_llm}')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:06:47.999683Z","iopub.execute_input":"2023-12-03T18:06:48.000129Z","iopub.status.idle":"2023-12-03T18:06:48.011360Z","shell.execute_reply.started":"2023-12-03T18:06:48.000094Z","shell.execute_reply":"2023-12-03T18:06:48.009803Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Conditional probability of \"the\" given LLM: 0.0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Derive Top 10 words that predict each class","metadata":{}},{"cell_type":"code","source":"top_words_llm = sorted(vocab, key=lambda word: word_probs[1][word], reverse=True)[:10]\ntop_words_human = sorted(vocab, key=lambda word: word_probs[0][word], reverse=True)[:10]\n\nprint(f'Top 10 words predicting LLM: {top_words_llm}')\nprint(f'Top 10 words predicting Human: {top_words_human}')","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:07:03.873482Z","iopub.execute_input":"2023-12-03T18:07:03.873971Z","iopub.status.idle":"2023-12-03T18:07:03.888475Z","shell.execute_reply.started":"2023-12-03T18:07:03.873935Z","shell.execute_reply":"2023-12-03T18:07:03.886853Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Top 10 words predicting LLM: ['electoral', 'votes', 'college', 'state', 'vote', 'win', 'president', 'popular', 'candidate', 'majority']\nTop 10 words predicting Human: ['electoral', 'people', 'car', 'college', 'vote', 'cars', 'states', 'would', 'president', 'usage']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# compare effect of smooting","metadata":{}},{"cell_type":"code","source":"def train_naive_bayes(data, vocab, smoothing_method='laplace', smoothing_parameter=1):\n    word_counts = {class_: defaultdict(int) for class_ in np.unique(data['generated'])}\n    class_counts = defaultdict(int)\n\n    for _, row in data.iterrows():\n        label = row['generated']\n        class_counts[label] += 1\n        for word in row['processed_text']:\n            if word in vocab:\n                word_counts[label][word] += 1\n\n    total_docs = len(data)\n    word_probs = {class_: {} for class_ in word_counts}\n    class_probs = {class_: class_counts[class_] / total_docs for class_ in class_counts}\n\n    for class_, word_count in word_counts.items():\n        for word in vocab:\n            if smoothing_method == 'laplace':\n                word_probs[class_][word] = (word_count.get(word, 0) + smoothing_parameter) / \\\n                                           (class_counts[class_] + smoothing_parameter * len(vocab))\n            elif smoothing_method == 'add-k':\n                word_probs[class_][word] = (word_count.get(word, 0) + smoothing_parameter) / \\\n                                           (class_counts[class_] + smoothing_parameter)\n            else:\n                raise ValueError('Invalid smoothing method')\n\n    return class_probs, word_probs\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:07:18.792894Z","iopub.execute_input":"2023-12-03T18:07:18.793393Z","iopub.status.idle":"2023-12-03T18:07:18.810866Z","shell.execute_reply.started":"2023-12-03T18:07:18.793343Z","shell.execute_reply":"2023-12-03T18:07:18.809306Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Naive Bayes with Laplace smoothing (add-one)\nclass_probs_laplace, word_probs_laplace = train_naive_bayes(train_data, vocab, smoothing_method='laplace', smoothing_parameter=1)\n\n# Train Naive Bayes with add-k smoothing\nclass_probs_addk, word_probs_addk = train_naive_bayes(train_data, vocab, smoothing_method='add-k', smoothing_parameter=0.1)\n\n# Evaluate classifiers with different smoothing\ndev_data['predicted_laplace'] = dev_data['text'].apply(lambda text: classify(text, class_probs_laplace, word_probs_laplace, vocab))\ndev_data['predicted_addk'] = dev_data['text'].apply(lambda text: classify(text, class_probs_addk, word_probs_addk, vocab))\n\naccuracy_laplace = np.mean(dev_data['predicted_laplace'] == dev_data['generated'])\naccuracy_addk = np.mean(dev_data['predicted_addk'] == dev_data['generated'])\n\nprint(f'Accuracy with Laplace smoothing: {accuracy_laplace*100}%')\nprint(f'Accuracy with add-k smoothing: {accuracy_addk*100}%')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-03T18:07:33.725922Z","iopub.execute_input":"2023-12-03T18:07:33.726425Z","iopub.status.idle":"2023-12-03T18:07:49.609784Z","shell.execute_reply.started":"2023-12-03T18:07:33.726362Z","shell.execute_reply":"2023-12-03T18:07:49.608480Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Accuracy with Laplace smoothing: 99.27536231884058%\nAccuracy with add-k smoothing: 95.65217391304348%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}